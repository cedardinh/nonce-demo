# 111最终方案（最终设计稿）

> 约束声明：本文档**仅基于阶段二的问题与风险清单**进行收敛设计，并以你在“选择”中确定的 A/B 方案组合为前提，给出可落地的整体系统方案与权衡说明。

---

## 1. 目标、边界与验收口径

### 1.1 目标（解决阶段二“高/中”问题）

- **统一正确性边界（高）**：不再并存多套互斥机制（lease/fencing vs Redis 锁 vs CAS-only），以 **Postgres lease + fencing** 作为唯一正确性边界。
- **统一领域载体（高）**：采用 **`managed_tx` 作为 nonce 与状态机的唯一权威载体**（nonce 绑定交易状态机推进）。
- **提交与终局解耦（高）**：终局由后台 receipt/finality 推进；提交成功（获得 txHash）不等于终局。
- **不对外暴露 confirmations（高，问题4 选 C）**：系统内部处理 reorg/finality；对外只暴露“终局状态/稳定结果”，而不是 confirmations 链细节。
- **nonce 分配（问题5）**：采用 **三端取最大 `max(chain, cache, db)`** 的分配思路（参考 FireFly 思路），目标是“不重用/不回退”，并允许链上可能出现 gap。
- **补救机制（高，问题6 选 B）**：系统支持“占位/取消/替换”等 **可插拔补救动作**，但通过 **hook/policy 由业务决定是否启用与具体策略**；默认可不自动改写业务交易语义。若头部 nonce 长期卡住，进入 STUCK + 强告警 + 运维 SOP，并可按策略触发补救。
- **写入权限证明统一（高，问题7 选 A）**：所有关键写入使用 fencing_token；彻底消除“迟到写覆盖”的安全漏洞。
- **性能路径收敛（高，问题8/9 选 A）**：采用 **writer worker 串行 + batch**；严格 DB 权威（不引入 Redis-DB 不一致窗口）。
- **状态机/术语统一（中，问题10 选 A）**：统一使用“交易状态机词汇”，nonce 生命周期从 tx 状态派生（不再用 allocation 三态作为对外主语）。
- **扩展点统一（中，问题11 选 A）**：按端口/适配器（Ports/Adapters）分层，抽象 ChainConnector/SignService/（可选）EventPublisher 等。
- **对外契约（中，问题12 选 A）**：默认只提供查询轮询（poll）；不提供 webhook/MQ 推送模式作为核心路径。
- **并发窗口（中，问题13 选 B）**：允许多 in-flight，但必须监控 pending 堆积；发现“头部卡住/超时”触发补救（resubmit/告警/人工介入）。
- **幂等（中，问题14）**：requestId 可选；提供两条创建入口：带 requestId 走幂等，不带则不做请求级幂等。

### 1.3 验收口径（与阶段二风险对应）

- **故障切换窗口旧节点写入被硬切断**：任何旧 token 的关键写入影响行数为 0（FENCED），不得覆盖新 leader 写入。
- **同 submitter 下 nonce 不重用、不回退**：在 DB 权威与三端取最大下，分配的 nonce 单调不减。
- **提交≠终局**：接口可看到 TRACKING/INFLIGHT；终局由后台推进到 CONFIRMED/FAILED_FINAL/STUCK。
- **pending 堆积可观测**：能监控“队列长度、最老 pending 时长、头部卡住次数、resubmit 次数”等。

---

## 2. 总体架构：分层、模块边界与依赖方向

### 2.1 分层（Ports/Adapters）

- **API 层（Inbound）**
  - `TxController`：创建/查询交易；提供“带 requestId 幂等”和“不带 requestId 非幂等”两条入口。
  - `TxCompletionController`（可选但建议）：提供“终局结果 feed”的轮询接口，降低下游扫描成本（仍属于 poll 模式）。
- **应用层（Application / Use Cases）**
  - `CreateTxUseCase`：创建交易意图、抢租、幂等校验、入 writer 队列。
  - `GetTxUseCase`：按 txId / (submitter, requestId) 查询。
  - `ResubmitSchedulerUseCase`：扫描候选并触发重提（leader-only + fenced claim）。
  - `ReceiptSchedulerUseCase`：调度 receipt 检查（leader-only 或可并行计算但 fenced 写回）。
  - `ListTxCompletionsUseCase`（可选但建议）：按序列/时间分页返回终局交易列表（poll-friendly）。
- **领域层（Domain）**
  - `ManagedTx`：聚合根（submitter、requestId、nonce、txHash、state、错误、时间戳等）。
  - `TxStateMachine`：统一状态机（见 4.2）。
  - `Lease`：执行权语义（leader、token、expiresAt）。
- **基础设施层（Infrastructure / Adapters）**
  - `LeaseRepository`（Postgres）
  - `TxRepository`（Postgres）
  - `NonceCursorRepository`（Postgres + 可选本地 cache）
  - `TxCompletionRepository`（Postgres，可选但建议）：为“完成 feed”提供顺序可消费的数据源。
  - `ChainConnector`（EVM RPC/Web3j 等）
  - `StuckResolutionHook`（可插拔：占位/取消/替换等补救动作的业务决策与实现）
  - `TransactionWriter`（worker pool + batch）
  - `ReceiptChecker`（worker pool）
  - `FinalityManager`（内部处理 reorg/finality；不对外输出 confirmations）
  - `Metrics/Logging`（可观测性）

### 2.2 依赖方向（强约束）

- API → Application → Domain
- Infrastructure **实现** Application/Domain 所依赖的端口接口（Repository/Connector），但 **Application/Domain 不反向依赖 Infrastructure**
- 所有“关键写入”（nonce 分配、txHash、状态推进、调度时间、终局回写）**必须经由 fenced 写入路径**（见 3.2）

### 2.3 核心数据流（高层）

#### 2.3.1 创建交易（带/不带 requestId）

1. API 接收 `CreateTx`：
   - 若提供 `requestId`：走幂等创建入口
   - 若不提供：走非幂等入口
2. Application 将请求路由到 `TransactionWriter`（按 `hash(submitter)%N`）。
3. Worker 内：
   - 获取/续租 lease，拿到 `(isLeader, fencingToken)`
   - 幂等检查（若 requestId 存在）
   - 分配 nonce（`max(chain, cache, db)`）
   - 事务内写入 `managed_tx`（nonce + state）与游标更新（均 fenced）
   - 异步触发 submit（同 worker 内或提交队列）
4. 提交获得 `txHash` 后 fenced 写入 txHash 与 state=TRACKING（提交≠终局）。
5. 将 tx 放入 receipt 检查调度队列。

#### 2.3.2 终局推进（receipt + finality，内部处理 reorg）

1. `ReceiptChecker` 拉取 receipt（按 txHash）。
2. fenced 写入 receipt、blockNumber/blockHash 等最小证据。
3. `FinalityManager` 内部基于链视图一致性与 reorg 检测推进：
   - 达到终局阈值 → fenced 写入 CONFIRMED / FAILED_FINAL
   - 若长期不可达 → fenced 写入 STUCK（仅告警，不自动填洞/替换）
4. 对外仅通过查询接口暴露最终状态（不暴露 confirmations 链）。

#### 2.3.3 重提（resubmit）

1. `ResubmitScheduler` 周期扫描候选（state=TRACKING 且 receipt 为空且超过 interval，或 pending 堆积阈值触发）。
2. 对每条候选按 submitter 路由 worker：
   - 抢租确认 leader
   - fenced claim（更新 `next_resubmit_at` / `last_submit_at`）后再发 RPC（避免重复副作用）
   - 提交同 nonce、同 payload（不替换/不取消）
   - fenced 更新 attempt/last_error 等

---

## 3. 关键机制设计（逐条对应阶段二问题）

### 3.1 执行权：Postgres Lease + Fencing（对应问题1/7，高）

#### 为什么这样设计
- 阶段二指出存在多套互斥“正确性边界”，会导致故障切换/双活窗口写污染。
- 统一为 DB lease/fencing 能提供**可证明的硬切断**：旧 token 写入必然失败（影响行数=0）。

#### 相比原混合方案解决了什么
- 消除 Redis 锁、lockOwner、CAS-only 等多机制并存导致的语义漂移。
- 解决“旧节点迟到回写覆盖新节点”的高危风险。

#### 代价/限制
- 所有关键写入 SQL/Repository 都需要携带 `node_id + fencing_token` 校验（侵入性高）。
- 需要运维 lease 续租参数（duration/renewInterval/clockSkewAllowance）。

#### 设计要点（落地约束）
- 表：`submitter_lease(submitter PK, owner_node, fencing_token, expires_at, updated_at)`
- acquire/renew：`SELECT ... FOR UPDATE`，不存在则 insert；owner=self 且未过期则续租；过期则抢占并 token++；未过期且 owner!=self 则 not leader。
- fenced 写入：所有关键 UPDATE/INSERT 必须验证：
  - lease 未过期（DB `now()`）
  - owner_node == self
  - fencing_token == token

---

### 3.2 节点内串行化 + TransactionWriter 批处理（对应问题8/9，高）

#### 为什么这样设计
- 阶段二“性能路径分裂”与“CAS 重试风暴”风险：热点 submitter 会产生高冲突重试。
- 按 submitter 路由到固定 worker 可以把冲突变成**顺序写入**，并在批处理中减少 DB 往返。

#### 相比原方案解决了什么
- 由“并发碰撞+重试”转为“可控串行+批处理”，更容易推导性能与故障模式。
- 在严格 DB 权威（问题9 选 A）下，仍可通过 batch 提升吞吐。

#### 代价/限制
- 引入 worker/队列/批处理框架：需要队列背压、批次失败重试、熔断与监控。
- 单 submitter 的吞吐受限于其 worker 单线程节奏（但可控）。

#### 落地约束
- worker 数固定（例如 N=256/512）；`workerIndex=hash(submitter)%N`。
- batch 内必须保证：同一 submitter 的 allocate/insert/update/claim 顺序一致。
- batch 失败要保证：本地 nonce cache 回滚/清理（见 3.4）。

---

### 3.3 领域载体统一：`managed_tx` 权威（对应问题2/10，高/中）

#### 为什么这样设计
- 阶段二指出“交易即 nonce 载体 vs allocation 独立表”会导致双状态源与责任边界不清。
- 统一为 managed_tx 可以承载：nonce、txHash、终局证据、重提调度、错误、可观测轨迹。

#### 相比原方案解决了什么
- 把“nonce 生命周期/终局推进/重提/观测”统一挂到同一聚合根，避免散落在 allocation/外部系统。
- 解决状态机词汇不统一（问题10），对外以交易状态机为准。

#### 代价/限制
- 需要新增表结构与状态机推进逻辑；对现有 `allocation` 模型与 `src` demo 代码是高侵入。
- 数据迁移与历史数据兼容需要额外方案（本文不展开）。

---

### 3.4 Nonce 分配：三端取最大 `max(chain, cache, db)`（对应问题5，高）

#### 为什么这样设计
- 阶段二指出分配策略存在冲突；你选择了“参考 FireFly 思路做三端取最大”，目标是避免重用/冲突并在多源视图下更稳。

#### 相比原方案解决了什么
- 相比只依赖 DB 或只依赖缓存，三端取最大降低“nonce too low/重用”的概率。
- 在多节点/故障恢复场景下更易自愈（以链上 pending nonce 兜底）。

#### 代价/限制
- 不能硬保证链上无 gap（补救 hook 即使启用，也不等价于“全场景严格无 gap”保证）。
- 需要 ChainConnector 提供 `getPendingNonce(submitter)`，并引入本地缓存的回滚/清理规则。

#### 设计细节（可执行规则）
- **db 端**：`submitter_nonce_cursor.next_nonce`（权威的“下一次将分配”的 nonce）。
- **cache 端（可选）**：节点内 LRU（按 submitter）缓存 `nextNonce` 与 `updatedAt`；缓存仅用于加速，批次失败必须清理。
- **chain 端**：`eth_getTransactionCount(submitter, "pending")` 得到 `chainNext`。
- **取最大**：`next = max(chainNext, cacheNext, dbNext)`。
- 分配一批 nonce：从 next 连续递增。
- 成功提交事务后：写回 `submitter_nonce_cursor.next_nonce = next + batchCount`，并更新 cache。
- **事务/批次失败（硬约束）**：必须清理该 submitter 的缓存条目（防止“缓存递增但 DB 未提交”导致跳号/错误分配）。
- **缓存过期策略（建议硬化为配置）**：引入 `nonceStateTimeout`（类似 FFTM），当缓存存在但超过阈值时必须视为过期，回落执行 `max(chain, db, expired-cache)` 的对齐决策（过期缓存仍可参与比较，避免“DB 落后于未提交批次的缓存值”带来的回退风险）。

---

### 3.5 提交与终局解耦（对应问题3，高）

#### 为什么这样设计
- 阶段二指出“txHash 即 USED”与“确认驱动终局”冲突；你选择 A：终局由后台推进。

#### 相比原方案解决了什么
- 避免把“广播成功”误当作“最终成功”，为 reorg 与长 pending 留出状态表达空间。

#### 代价/限制
- 业务侧需要接受：创建/提交成功后仍可能长时间处于 TRACKING。
- 系统必须提供稳定的查询与可观测性，指导运维处理 STUCK。

#### “txHash 灰区”补齐能力（可选但建议，工程化兜底）

> 对齐 FFTM 的经验：当节点已接收交易但本地未拿到 txHash（超时/网络错误）时，会出现 `known_transaction/nonce_too_low` 但本地无 hash 的灰区。

- **端口扩展（可选）**：`ChainConnector` 增加“仅签名/重算预期 txHash”能力（或等价能力），用于在灰区下尝试补齐 txHash：
  - `signOnly(...)` / `recomputeTxHash(...)` / `deriveExpectedHash(...)`（命名与具体实现由业务/链实现决定）
- **无此能力时的口径**：进入 STUCK + 告警 + SOP（不让系统默默“认为失败/成功”）。
- **有此能力时的口径**：允许将灰区收敛为可自动恢复（补齐 txHash 后继续 TRACKING/receipt 流程）。

---

### 3.6 reorg/finality：内部处理，不对外暴露 confirmations（对应问题4，高，选 C）

#### 为什么这样设计
- 阶段二指出 confirmations/newFork 协议会放大对外契约复杂度；本方案选择不输出 confirmations 链，只输出终局结果。

#### 相比原方案解决了什么
- 降低对外协议复杂度，减少下游必须理解 newFork 的负担。

#### 代价/限制
- 牺牲“确认链可审计”的对外能力；审计更多依赖内部日志/指标与最小证据（receipt/block 信息）。

#### 落地口径
- DB 仅持久化最小证据：receipt、blockNumber、blockHash、确认达阈值的 `confirmed_at`。
- finality 逻辑内部处理 reorg：必要时回退状态并重新推进（对外只看到状态变化）。

#### 内部执行契约（建议硬约束，避免“队头阻塞/紧密自旋/链视图漂移”）

- **ReceiptChecker 行为**
  - `NotFound`：视为“尚未就绪”，更新 `last_receipt_check_at`，按延迟策略重入队；不视为错误、不阻塞其他交易。
  - **非 NotFound 错误**：必须退避（backoff）并将条目移到队尾，避免单条卡死/紧密重试拖垮系统。
- **FinalityManager 行为**
  - **链视图一致性**：在一次推进循环中，对同一高度的 block 查询结果必须一致（对 `getBlockByNumber` 做循环内缓存），避免把不同 fork 的块混入同一次计算导致误判。
  - **reorg 回退**：若检测到链不一致，需要允许从“接近终局/已推进状态”回退到可继续追踪的状态（对外仅体现最终状态变化，不输出 confirmations）。

---

### 3.7 可插拔补救：占位/取消/替换 + STUCK/SOP（对应问题6，高，选 B）

#### 为什么这样设计
- 阶段二明确“严格无 gap”与“不改写交易语义”存在张力；本方案将“是否改写/如何补救”从核心流程中剥离出来，通过 **可插拔 hook/policy** 兼容不同业务约束。

#### 相比原方案解决了什么
- 让“不可消除风险”显式化：通过 STUCK 与告警/流程承接，且在需要时允许触发“可控的补救动作”，而不是隐式跳号或静默放弃。

#### 代价/限制
- 若启用补救（占位/取消/替换），系统将产生**额外链上行为**与更复杂的审计/风控要求（例如签名权限、费率策略、可观测与回滚边界）。
- 若不启用补救，一旦某 nonce 永久卡住，后续 nonce 交易可能被链规则阻塞并出现 pending 堆积，需要运维 SOP。

#### 补救 Hook（可插拔能力边界）

> 目标：兼容不同场景与业务约束，让系统“不替你做最终决策”，但具备执行能力。

**Hook 的核心定位**
- **业务可决定/可自定义实现的内容**（你关心的部分）
  - **何时触发补救**：阈值策略（头部卡住时长、pending 堆积阈值、重提次数上限、错误类型白名单/黑名单等）
  - **选择哪种补救动作**：NOOP / CANCEL / REPLACE / PLACEHOLDER（或业务自定义动作）
  - **如何构造补救交易**：目标地址/数据/payload、费率参数、是否 bump、签名来源（业务自持私钥/外部签名服务）、是否允许替换原业务交易语义
  - **补救后的状态推进策略**：是否继续 TRACKING、是否直接 STUCK、是否降级为人工介入、以及告警分级
  - **审计与风控**：对每次补救动作输出业务自定义审计字段（工单号/业务单号/责任人/解释文本等）
- **系统必须强制保证的内容**（不可被 hook 绕过）
  - 所有关键写入必须 fenced（旧 token 写入必须失败）
  - 任何可能产生链上副作用的动作必须先 fenced claim（避免多节点重复执行）

**Hook 触发点（系统调用 Hook 的时机）**
- **Head-of-line 卡住**：最前面的/最老的 `TRACKING` tx 超过阈值仍无 receipt/终局
- **pending 堆积**：pending 队列长度或 oldest age 超过阈值，且判断“头部卡住明显”
- **业务显式触发**：业务侧调用“处理卡住交易/nonce”接口（可选管理端）

**Hook 返回的动作类型（示例）**
- **NOOP**：不做链上补救，仅保持 resubmit + 监控/告警（默认实现应为 NOOP）
- **CANCEL**：构造“取消/自转账”类交易消费 nonce（需要业务允许这类语义）
- **REPLACE**：构造同 nonce 的替换交易（需要业务允许替换与费率策略）
- **PLACEHOLDER**：构造占位交易以推进 nonce（需要业务允许系统交易）

**建议的 Hook 契约（示意）**

```java
public interface StuckResolutionHook {
  ResolutionDecision decide(ResolutionContext ctx);
}

public final class ResolutionContext {
  public final String submitter;
  public final String txId;
  public final long nonce;
  public final String txHash;          // may be null
  public final String state;           // TRACKING / ...
  public final int submitAttempts;
  public final String lastError;       // may be null
  public final long ageMillis;         // how long it's been stuck/tracking
  public final long pendingQueueDepth; // for this submitter (or global)
  // ... plus business metadata if available (requestId, bizId, etc.)
}

public final class ResolutionDecision {
  public enum Action { NOOP, CANCEL, REPLACE, PLACEHOLDER }
  public final Action action;
  public final String reason; // for audit & explainability
  // For CANCEL/REPLACE/PLACEHOLDER: provide a builder/descriptor or rawTx via a business adapter
}
```

**执行约束（系统侧硬约束）**
- **leader-only + fenced claim** 后才能执行 Hook 决策对应的链上动作（避免多节点重复补救）
- 必须记录 `submitter/tx_id/nonce/action/node_id/token/decision_reason` 的审计日志与指标
- Hook 应设计为**幂等可重入**：同一 tx 在重复触发时不会导致不可控的重复副作用（系统也会通过 claim 限流）

---

### 3.8 对外接口：仅轮询查询（对应问题12，中，选 A）

#### 为什么这样设计
- 阶段二指出事件推送会引入一致性与投递复杂度；本方案选择最小稳定面：poll 查询。

#### 相比原方案解决了什么
- 降低系统耦合与失败模式数量，缩短落地路径。

#### 代价/限制
- 下游实时性与推送解耦能力下降；查询压力需要通过索引与缓存策略承接（本方案不引入 Redis 权威缓存）。

---

### 3.9 并发窗口：允许多 in-flight + pending 堆积监控与补救（对应问题13，中，选 B）

#### 为什么这样设计
- 阶段二指出 single in-flight 与吞吐扩展冲突；本方案允许多 in-flight，但必须以监控与补救控制风险。

#### 相比原方案解决了什么
- 在不牺牲整体吞吐的前提下，把“堆积风险”转成可观测、可治理的问题。

#### 代价/限制
- 需要明确“阈值与动作”：例如 oldest pending age、queue length、resubmit 次数、卡头检测等。

#### 补救动作（系统内可实现的最小闭环）
- 若 pending 堆积超过阈值：
  - 优先检查最老/头部 tx 是否超时、是否长期无 receipt；
  - 触发 resubmit（同 nonce 同 payload）；
  - 超过上限/长期无进展 → STUCK + 告警。

---

### 3.10 幂等：requestId 可选（对应问题14，中）

#### 为什么这样设计
- 阶段二指出文档强调 requestId 幂等但现状实现未体现；你要求作为可选项并提供两条方法。

#### 相比原方案解决了什么
- 在 requestId 存在时可防止重复请求消耗资源；在缺失时保持 API 兼容与简单性。

#### 代价/限制
- 不带 requestId 的调用无法获得请求级幂等保证；需要业务侧自行承担重试幂等。

#### 幂等的硬约束（对齐 FFTM：冲突请求不得消耗 nonce）

- **两段式幂等检查（建议硬约束）**
  - **入口预检（pre-check）**：当 requestId 存在时，先查 `(submitter, requestId)` 是否已有 `managed_tx`，若命中直接返回 existing（避免进入后续链查询/资源消耗）。
  - **writer 批前二次校验（pre-insert check）**：在 `TransactionWriter` 的 batch 内、nonce 分配之前再次校验（覆盖并发窗口）。
- **关键约束：冲突请求不得消耗 nonce**
  - 一旦判定幂等冲突，该 op 必须标记为 “conflict”，并从 `assignNonces`/游标推进中排除（类似 FFTM 的 `sentConflict` 语义）。
  - 对外返回应是可预期的“幂等命中/冲突语义”（由 API 契约决定是 200 existing 或 409 conflict），但不得以 500 形式暴露为系统错误。

---

## 4. 数据模型（Postgres 权威）

### 4.1 `submitter_lease`（执行权）

- `submitter`（PK）
- `owner_node`
- `fencing_token`（单调递增）
- `expires_at`
- `updated_at`

### 4.2 `managed_tx`（权威交易/nonce 载体）

最小必备字段（可按需扩展）：

- `tx_id`（PK）
- `submitter`
- `request_id`（可空；若存在建议建立 `(submitter, request_id)` 唯一约束）
- `nonce`（分配后不可变）
- `payload`（业务交易参数/签名材料引用）
- `tx_hash`（可空，提交后填充）
- `state`（统一状态机）
- `sub_state`（可选：STALE/…）
- `last_submit_at`
- `next_resubmit_at`
- `submit_attempts`
- `last_error`
- `receipt`（可空）
- `confirmed_at`（可空）
- `fencing_token`（审计/写入证明）
- `created_at`、`updated_at`

### 4.4 `tx_completions`（可选但建议：终局结果 feed）

> 目的：在“poll-only”的对外契约下，为下游提供高效的“按序消费终局结果”能力，避免扫描 `managed_tx` 大表。

- 最小字段：
  - `seq`（单调递增）
  - `tx_id`
  - `time`（终局时间）
  - `status`（例如 CONFIRMED / FAILED_FINAL / STUCK）
- 写入时机：当 `managed_tx` 进入终局态时写入（可在 writer batch 尾部统一落库，必要时通过表级/行级机制保证可单调消费）。

#### 状态机（对外统一）

- `CREATED`：已接收创建意图（可选，如直接分配可略）
- `ALLOCATED`：已分配 nonce 并持久化
- `TRACKING`：已提交（有 txHash），等待 receipt/finality
- `CONFIRMED`：达到终局阈值（内部 finality 达成）
- `FAILED_FINAL`：终局失败（receipt 显示失败且可判定终局）
- `STUCK`：长期不可终局（不自动填洞/取消/替换，仅告警与人工介入）

### 4.3 `submitter_nonce_cursor`（db 端游标）

- `submitter`（PK）
- `next_nonce`
- `fencing_token`
- `updated_at`

---

## 5. 可观测性与运维信号（覆盖阶段二风险点）

### 5.1 必备日志维度

- `submitter`
- `tx_id`
- `node_id`
- `fencing_token`
- `state`（前后变化）
- `nonce`、`tx_hash`（若有）

### 5.2 必备指标（示例）

- `lease_acquire_total{result}`
- `lease_fenced_total`
- `writer_queue_depth{worker}`
- `tx_create_total{result}`
- `tx_submit_total{result}`
- `receipt_check_total{result}`
- `pending_oldest_age_seconds{submitter?}`（submitter 可脱敏/采样）
- `resubmit_total{result}`
- `stuck_total`

### 5.3 告警建议（与问题13/6 对应）

- fenced 激增（可能双活/参数异常/DB 抖动）
- receipt backlog 持续增长（终局推进失速）
- pending oldest age 超阈值（头部卡住）
- STUCK 增长（需要人工介入）

---

## 6. 关键限制汇总（显式声明）

- **不保证链上无 gap**：采用三端取最大与“不填洞”边界时，gap 可能出现；系统保证“不重用/不回退、可观测、可追踪、可告警”。
- **启用补救策略会改变系统的链上行为版图**：补救（占位/取消/替换）需要业务通过 hook 明确授权与决策；否则默认不自动执行，仅依赖 resubmit/监控/告警与 SOP。
- **DB 权威带来的吞吐上限**：不引入 Redis 权威层与不一致窗口（问题9 选 A），吞吐主要由 DB + writer batch 决定。
- **不对外暴露 confirmations**：降低对外契约复杂度，但外部审计需依赖查询状态与内部日志/指标。

---

## 7. 与阶段二“高/中问题”的对照表（覆盖性检查）

- **问题1（高）**：统一正确性边界 → 3.1（lease+fencing）
- **问题2（高）**：统一载体 → 3.3（managed_tx）
- **问题3（高）**：提交与终局解耦 → 3.5
- **问题4（高）**：不暴露 confirmations → 3.6
- **问题5（高）**：三端取最大 → 3.4
- **问题6（高）**：可插拔补救（占位/取消/替换）+ STUCK/SOP → 3.7
- **问题7（高）**：写入证明统一 token → 3.1（并约束全写入 fenced）
- **问题8（高）**：writer worker + batch → 3.2
- **问题9（高）**：严格 DB 权威 → 3.2/6
- **问题10（中）**：状态机统一 → 4.2
- **问题11（中）**：扩展点统一 → 2.1/2.2
- **问题12（中）**：仅轮询 → 3.8
- **问题13（中）**：多 in-flight + 监控补救 → 3.9
- **问题14（中）**：requestId 可选幂等 → 3.10

---

## 8. 渐进式改造步骤（与当前 `src` 对齐）

> 目标：避免“一次性重写”。每一步都保持可编译、可演示、可回滚。

### 里程碑 1（已在代码中落地：新 txmgr 骨架与关键硬约束）

- **新增 txmgr 子模块（并行存在）**：不破坏现有 `core`/`demo` 的 allocation 方案，先让新架构可运行。
- **DB 权威数据模型与 mapper**：`submitter_lease` / `submitter_nonce_cursor` / `managed_tx` / `tx_completions`
- **LeaseManager（DB 时间 + fencing token）**
- **TransactionWriter（worker 路由 + batch）**
- **两段式幂等（pre-check + pre-insert）且冲突不消耗 nonce**
- **max(chain, cache, db) nonce 分配（含 nonceStateTimeout 与失败清 cache）**
- **poll-only API**：`POST /api/v1/tx`、`GET /api/v1/tx/{id}`、`GET /api/v1/tx/by-request`、`GET /api/v1/tx/completions`

### 里程碑 2（建议下一步）：receiptChecker + finalityManager（内部契约落地，不对外暴露 confirmations）

- **ReceiptChecker**：NotFound 不算错 + backoff + 队尾重排（防队头阻塞）
- **FinalityManager**：循环内链视图一致性缓存 + reorg 回退推进
- **终局写入**：进入 `CONFIRMED/FAILED_FINAL/STUCK` 时写入 `tx_completions`

### 里程碑 3：resubmitScheduler + pending 堆积治理

- 周期扫描 `TRACKING` 且无 receipt 的交易，按 submitter 路由到 writer
- 通过 fenced claim 更新 `next_resubmit_at` 后再发送（避免多节点重复副作用）
- 结合 pending 堆积阈值触发“头部卡住”治理

### 里程碑 4：补救 Hook（业务自定义）

- 引入 `StuckResolutionHook` 的落地实现与管理端触发入口
- 把 “NOOP/CANCEL/REPLACE/PLACEHOLDER” 变成业务可插拔策略（并记录审计字段）


